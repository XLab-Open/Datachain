Metadata-Version: 2.4
Name: datachain
Version: 0.1.0
Summary: A generic class registration factory for dynamic class management
Author-email: XLab-Open <contact@xlab-open.org>
License: MIT
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: rich>=14.0.0
Requires-Dist: typer>=0.16.1
Requires-Dist: typing-extensions>=4.14.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: pytest-mock>=3.10.0; extra == "dev"
Requires-Dist: pytest-xdist>=3.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: flake8<7.2.0,>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Dynamic: license-file

<div align="center">

<img src="./docs/images/datachain.png" width="600" height="160">

<h2 align="center">AI model deployment based on embedded domain controller platforms</h2>


[<span style="font-size:20px;">**Architecture**</span>](./docs/framework.md)&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[<span style="font-size:20px;">**Documentation**</span>](https://liwuhen.cn/CVDeploy-2D)&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[<span style="font-size:20px;">**Blog**</span>](https://www.zhihu.com/column/c_1839603173800697856)&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[<span style="font-size:20px;">**Roadmap**</span>](./docs/roadmap.md)&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[<span style="font-size:20px;">**Slack**</span>](https://app.slack.com/client/T07U5CEEXCP/C07UKUA9TCJ)

<p align="right">
  üåê <b>Language</b> | ËØ≠Ë®ÄÔºö
  <a href="./docs/README.zh-CN.md">üá®üá≥ ‰∏≠Êñá</a>
</p>

---

![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=for-the-badge)
![ARM Linux](https://img.shields.io/badge/ARM_Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)
![Ubuntu](https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white)
![NVIDIA](https://img.shields.io/badge/NVIDIA-%2376B900.svg?style=for-the-badge&logo=nvidia&logoColor=white)
![Performance](https://img.shields.io/badge/Performance-Optimized-red?style=for-the-badge)
![GPU Accelerated](https://img.shields.io/badge/GPU-Accelerated-76B900?style=for-the-badge&logo=nvidia&logoColor=white)

The repository focuses on converting formats across multiple open-source datasets and offers serialization capabilities to unify data representation.
</div>

# Getting Started
Visit our documentation to learn more.
## Installation
clone thee remote remote repository
```shell
git clone https://github.com/XLab-Open/Datachain
cd Datachain
```
Generate a local conda environment:
- uv (optional)
    ```shell
    - Install uv:  see the [installation guide](https://docs.astral.sh/uv/getting-started/installation/).
    - Create virtualenv:
        uv venv --python python3.11 and then source .venv/bin/activate.
    ```
- pip(optional)
    ```shell
    conda create -n datachain python==3.11 -y
    conda activate datachain
    ```
Install dependencies:
- uv (optional)
    ```shell
        uv pip install -e .
    ```

- pip (optional)
    ```shell
    pip install -r requirements.txt
    ```

## CLI Usage
You can also try out the CLI directly by running:
```shell
python -m cli.main
```
You will see a screen.
![layout](docs/images/layout.png)

# Performances
- Dataset:
    - pascal voc
        > The validation dataset is voc2012.
    - BDD100K
        > The validation dataset is BDD100K, which contains 70000 training samples and 10000 val samples.
    - nuscenes
        > The validation dataset is nuscenes-mini.
- Model: The deployed model is the 's' version of the YOLO multi-task network series.
- Quantize: Quantization was performed using NVIDIA's Post-Training Quantization (PTQ) method.

|SrcData|DstData|Cpu|
|:-:|:-:|:-:|
|voc|coco|-|
|nuImages|coco|-|
|BDD100K|coco|-|

# ![Contribute](https://img.shields.io/badge/how%20to%20contribute-project-brightgreen) Contributing
Welcome users to participate in these projects. Please refer to [CONTRIBUTING.md](./CONTRIBUTING.md) for the contributing guideline.We encourage you to join the effort and contribute feedback, ideas, and code. You can participate in Working Groups, Working Groups have most of their discussions on [Slack](https://app.slack.com/client/T07U5CEEXCP/C07UKUA9TCJ).

# ![TODO](https://img.shields.io/badge/how%20to%20contribute-project-brightgreen) TODO
- [ ] Add BDD100K
- [ ] Add API support for Caller

# References
- [Vllm: https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)
